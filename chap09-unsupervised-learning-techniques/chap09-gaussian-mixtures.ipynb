{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>chap9.2 Gaussian Mixtures</center>\n",
    "---\n",
    "\n",
    "A **<font color='red'>Gaussian mixture model (GMM)</font>** is a **probabilistic model** that assumes that the instances were generated from a mixture of several Gaussian distributions whose parameters are unknown.\n",
    "\n",
    "**<font color='crimson'>All the instances generated from a single Gaussian distribution form a cluster that typically looks like an ellipsoid (椭圆形). Each cluster can have a different ellipsoidal shape, size, density, and orientation.</font>**\n",
    "\n",
    "When you observe an instance, you know it was generated from one of the Gaussian distributions, but you are not told which one, and you don't know what the parameters of these distributions are.\n",
    "\n",
    "<Br>\n",
    "\n",
    "There are several GMM variants. In the <font color='crimson'>simplest variant</font>, implemented in the **`GaussianMixture`** class, you **must know in advance the number *k* of Gaussian distributions**. The dataset $X$ is assumed to have been generated through the following probabilistic process:\n",
    "\n",
    "- For each instance, a cluster is picked randomly from among $k$ clusters. The probability of choosing the $j^{th}$ cluster is defined by the cluster's weight $\\phi^{j}$. The index of the cluster chosen for the $i^{th}$ instance is noted $z^i$.\n",
    "\n",
    "|$k$|1|2|3|...|k|\n",
    "|:--| -- | -- | -- | -- | -- |\n",
    "|$p$|$\\phi^{1}$|$\\phi^{2}$|$\\phi^{3}$|...|$\\phi^{k}$|\n",
    "\n",
    "|$X$|$X_1$|$X_2$|$X_3$|...|$X_m$|comment|\n",
    "|:--| -- | -- | -- | -- | -- ||\n",
    "|cluster|$z^1$|$z^2$|$z^3$|..|$z^m$|$z^i\\in\\{1, 2, 3, ..., k\\}$|\n",
    "\n",
    "- If $z^i=j$, meaning the $i^{th}$ instance has been assigned to the $j^{th}$ cluster, the location $i^{th}$ of this instance is sampled randomly from the Gaussian distribution with mean $\\mu^{i}$ and covariance matrix $\\sum^{j}$. This is noted $\\textbf{x}^{i} \\sim N(\\mu^j, \\sum^j)$.\n",
    "\n",
    "The generative process can be represented as a graphical model.\n",
    "\n",
    "![xx](../figs/chap09-figs/gaussian-mixture-model-graph.png)\n",
    "<center><i>a graph of Gaussian mixture model, including its parameters (squares), random variable (circles), and their conditional dependencies (solid arrows)</i></center>\n",
    "\n",
    "\n",
    "  - 圆圈——随机变量；\n",
    "  - 正方形——固定值（即模型的参数）；\n",
    "  - 大矩形——plate，表示其中的内容重复多次；\n",
    "  - 每个矩形（plate）右下角的数字——表示里面内容可重复的次数。如，有 m 个随机变量 $z^i$ （从 $z^1$ 到 $z^m$）、m 个随机变量 $x^i$。同时，这里有 k 个均值 $\\mu^j$ 和 k 个协方差矩阵（covariance matrix）$\\sum^j$。最后，这里只有一个权重向量 $\\phi$（包含所有权重，从 $\\phi^1$ 到 $\\phi^k$）。\n",
    "  - 每个变量 $z^i$ 来自权重 $\\phi$ 的 categorical distribution。每个变量 $x^i$ 来自 normal distribution，其均值和协方差矩阵由其 cluster $z^i$ 决定。\n",
    "  - 实线箭头——表示条件依赖（conditional dependencies）。如，每个随机变量 $z^i$ 的概率分布依赖于权重向量 $\\phi$。如果箭头穿过 plate 边界，则表示对于 plate 的每次重复都有这种依赖。如，权重向量 $\\phi$ 决定了所有随机变量 $x^i$ 的概率分布。\n",
    "  - $z^i$ 到 $x^i$ 的波浪线——表示一个 switch：根据 $z^i$ 的值，实例 $x^i$ 将从不同的 gaussian distribution 中抽样。如，若 $z^i=j$，则 $\\textbf{x}^{i} \\sim N(\\mu^j, \\sum^j)$。\n",
    "  - 阴影节点（shaded node）——表明这个值已知。所以，在这种情况下，只有随机变量 $x^i$ 是已知的：他们被称为 <font color='red'>observed variables</font>。未知的随机变量 $z^i$ 被称为 <font color='red'>latent variables</font>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T12:28:56.509809Z",
     "start_time": "2020-03-09T12:28:54.976785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "np.random.seed(42)\n",
    "# warnings.filterwarnings(action='ignore', message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T12:29:00.338382Z",
     "start_time": "2020-03-09T12:29:00.334493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib version: 3.1.2\n",
      "numpy version: 1.18.1\n",
      "pandas version: 1.0.1\n",
      "scikit-learn version: 0.22.1\n"
     ]
    }
   ],
   "source": [
    "print('python version:', sys.version_info)\n",
    "print('matplotlib version:', mpl.__version__)\n",
    "print('numpy version:', np.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('scikit-learn version:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the dataset $X$, you typically want to start by estimating the weights $\\phi$ and all the distribution parameters $\\mu^i$ to $\\mu^k$, and $\\sum^i$ to $\\sum^k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T13:55:57.112861Z",
     "start_time": "2020-03-09T13:55:57.102129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1250, 2), (1250,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate isotropic Gaussian blobs for clustering.\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "x1, y1 = make_blobs(n_samples=1000, centers=((4, -4), (0, 0)), random_state=42)\n",
    "x1 = x1.dot(np.array([[0.374, 0.95], [0.732, 0.598]]))\n",
    "x2, y2 = make_blobs(n_samples=250, centers=1, random_state=42)\n",
    "x2 = x2 + [6, -8]\n",
    "x = np.r_[x1, x2]\n",
    "y = np.r_[y1, y2]\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T13:54:01.952312Z",
     "start_time": "2020-03-09T13:54:01.949939Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:22.437880Z",
     "start_time": "2020-03-09T14:32:22.334970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=3, n_init=10,\n",
       "                precisions_init=None, random_state=42, reg_covar=1e-06,\n",
       "                tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
       "                weights_init=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = GaussianMixture(n_components=3, n_init=10, random_state=42)\n",
    "gm.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:37.927317Z",
     "start_time": "2020-03-09T14:32:37.923599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39032584, 0.20961444, 0.40005972])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights of each mixture components.\n",
    "gm.weights_  # shape: (n_components,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:32:50.623310Z",
     "start_time": "2020-03-09T14:32:50.619887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05145113,  0.07534576],\n",
       "       [ 3.39947665,  1.05931088],\n",
       "       [-1.40764129,  1.42712848]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean of each mixture component.\n",
    "gm.means_    # shape: (n_components, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:34:52.613716Z",
     "start_time": "2020-03-09T14:34:52.609926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.68825143,  0.79617956],\n",
       "        [ 0.79617956,  1.21242183]],\n",
       "\n",
       "       [[ 1.14740131, -0.03271106],\n",
       "        [-0.03271106,  0.95498333]],\n",
       "\n",
       "       [[ 0.63478217,  0.72970097],\n",
       "        [ 0.72970097,  1.16094925]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The covariance of each mixture component.\n",
    "# The shape depends on `covariance_type`.\n",
    "gm.covariances_   # covariance_type='full'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|`covariance_type`|comment|attribute `covariances_`'s shape|\n",
    "| : -- | :-- | :--- |\n",
    "|'spherical'|Each component has its own general covariance matrix.|(n_components,)|\n",
    "|'tied'|All components share the same general covariance matrix.|(n_features, n_features)|\n",
    "|'diag'|Each component has its own diagonal covariance matrix.|(n_components, n_features)|\n",
    "|'full'|Each component has its own single variance.|(n_components, n_features, n_features)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T14:48:12.748763Z",
     "start_time": "2020-03-09T14:48:12.745040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.4, 0.4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "250 / 1250, 500 / 1250, 500 / 1250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked fine! The weights that were used to generate the data were 0.2, 0.4 and 0.4. And, the means and covariance matrices were very close to those found by the algorithm.\n",
    "\n",
    "**<font color='crimson'>This class relies on the Expectation Maximization (EM) algorithm</font>**, which has many similarities with the K-Means algorithm: it also initializes the cluster parameters randomly, then it repeats two steps until convergence.\n",
    "\n",
    "- 1st, assigning instances to clusters (this is called the <font color='red'>expectation step</font>),\n",
    "- 2nd, updating the clusters (this is called the <font color='red'>maximization step</font>).\n",
    "\n",
    "[The main difficulty in learning Gaussian mixture models from unlabeled data is that it is one usually doesn’t know which points came from which latent component ($z^i$, if one has access to this information it gets very easy to fit a separate Gaussian distribution to each set of points). Expectation-maximization is a well-founded statistical algorithm to get around this problem by an iterative process. First one assumes random components (randomly centered on data points, learned from k-means, or even just normally distributed around the origin) and computes for each point a probability of being generated by each component of the model. Then, one tweaks the parameters to maximize the likelihood of the data given those assignments. Repeating this process is guaranteed to always converge to a local optimum.](https://scikit-learn.org/stable/modules/mixture.html#estimation-algorithm-expectation-maximization)\n",
    "\n",
    "<font color='crimson'>In the context of clustering, you can think of EM as a generalization of K-Means</font> that not only **finds the cluster centers** ($\\mu^1$ to $\\mu^k$), but also **their size, shape, and orientation** ($\\sum^1$ to $\\sum^k$), as well as their relative weights ($\\phi^1$ to $\\phi^k$).\n",
    "\n",
    "**Unlike K-Means, EM uses soft cluster assignments, not hard assignments.**\n",
    "\n",
    "For each instance,\n",
    "\n",
    "- **during the expectation step**, the algorithm estimates the probability that it belongs to each cluster (based on the current cluster parameters).\n",
    "\n",
    "- Then, **during the maximization step**, each cluster is updated using *all* the instances in the dataset, with each instance weighted by the estimated probability that it belongs to that cluster. These probabilities are called the <font color='red'>responsibilities</font> of the clusters for the instances. During the maximization step, each cluster’s update will mostly be impacted by the instances it is most responsible for.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <center><b>WARNING</b></center><br>\n",
    "    Just like K-Means, EM can end up converging to poor solutions, so it needs to be run several times, keeping only the best solution. This is why <b>n_init</b> is set to 10 (default is 1).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:11:27.042145Z",
     "start_time": "2020-03-09T15:11:27.038794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether or not the algorithm converged.\n",
    "# True when convergence was reached in fit(), False otherwise.\n",
    "gm.converged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:11:55.608548Z",
     "start_time": "2020-03-09T15:11:55.605401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many iterations it took\n",
    "# Number of step used by the best fit of EM to reach the convergence\n",
    "gm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **you have an estimate of the location, size, shape, orientation, and relative weight of each cluster**, the model can easily assign each instance to the most likely cluster (hard clustering) or estimate the probability that it belongs to a particular cluster (soft clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:14:58.087530Z",
     "start_time": "2020-03-09T15:14:58.082862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.76815996e-01, 2.31833274e-02, 6.76282339e-07],\n",
       "       [9.82914418e-01, 1.64110061e-02, 6.74575575e-04],\n",
       "       [7.52377580e-05, 1.99781831e-06, 9.99922764e-01],\n",
       "       ...,\n",
       "       [4.31902443e-07, 9.99999568e-01, 2.12540639e-26],\n",
       "       [5.20915318e-16, 1.00000000e+00, 1.45002917e-41],\n",
       "       [2.30971331e-15, 1.00000000e+00, 7.93266114e-41]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soft clustering for new instances\n",
    "gm.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:15:05.737675Z",
     "start_time": "2020-03-09T15:15:05.733608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hard clustering for new instances\n",
    "gm.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
